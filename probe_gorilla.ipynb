{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d1da4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3,4,5,6\"\n",
    "\n",
    "os.environ['CUDA_PATH']='/usr/local/cuda-11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32fce034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ff17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdcb986b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"tiiuae/falcon-7b\")\n",
    "tokenizer.add_special_tokens({'pad_token': '<?>'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9593a5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize('find: searches files/directories by criteria; xargs: executes command with input items; grep: searches text by pattern; sort: sorts text file lines; awk: processes and reports text data; sed: filters/transforms text; echo: prints arguments to output; cut: removes sections from lines; head: outputs file start; cat: concatenates/displays file content; wc: counts lines/words/characters; sudo: executes command as another user; tail: outputs file end; ls: lists directory content; mkdir: creates directory; uniq: removes duplicate lines; tr: translates characters; rsync: remote file copy/sync; split: splits file into parts; read: reads input line; diff: compares files; cd: changes directory; ssh: remote shell access; tee: reads from stdin, outputs to stdout/file; df: disk space usage; chown: changes file owner/group; ln: creates file links; set: sets shell variables; comm: compares sorted files; mount: mounts filesystems; ifconfig: network interface config; column: formats text into columns; history: command history; shopt: shell option control; rev: reverses lines; tar: archive files; od: dumps files in octal; yes: outputs strings repeatedly; nl: numbers lines; ping: network reachability test.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aa934b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize(\"\"\"find: searches files/directories; -name \"pattern\": by name; -type d: directories; -type f: files; -perm: by permissions; -user: by owner; -group: by group; -size: by size; -mmin: modified minutes ago; -mtime: modified days ago; -exec: execute command on found items; -delete: delete found items.\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dbcf339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize(\"\"\"\"FDOPS (File and Directory Operations)\": Creating, deleting, modifying files and directories - basename, cd, ln, mkdir, rmdir, rm, cp, mv, touch, ls, find, pwd, chmod, chgrp, chown, pushd, popd, dirname.; \"TXTPROC (Text Processing)\": Manipulating or displaying text data - awk, cat, cut, diff, fold, grep, egrep, fgrep, nl, paste, sed, sort, uniq, column, rev, tac, tr, wc, join, seq, od.; \"SYSINFO (System Information and Management)\": Providing system info or managing resources - df, du, uname, top, mount, ifconfig, who, whoami, w, hostname, ps, pstree, date, md5sum, file, free, uptime, history, groups, shopt.; \"ARCH (File Compression and Archiving)\": Compressing, decompressing, or managing archives - tar, gzip, gunzip, bzip2, bunzip2, cpio, zcat, zless.; \"NET (Networking)\": Handling networking tasks - ping, ssh, scp, curl, wget, dig, ssh-keygen.; \"PROCCTRL (Job and Process Control)\": Managing running processes and jobs - bg, fg, jobs, kill, nohup, sleep, sudo, su, tmux.; \"HELPDOC (Help and Documentation)\": Providing help, manuals, or documentation - man, info, apropos, which.; \"PROGSCRIPT (Programming and Scripting)\": Used for programming tasks or script execution - bash, sh, source, gcc.; \"SHUTIL (Shell Utilities)\": Providing various utility functionalities - echo, read, set, env, bind, readlink, tee, watch, yes, true, false, split, mktemp, xargs.; \"SECOP (Secure Operations)\": Managing security or access control - chmod, chown, chgrp, sudo, su, shred.\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d759cd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize(\"\"\" cheat:man \n",
    "# To convert a man page to pdf:\n",
    "man -t bash | ps2pdf - bash.pdf\n",
    "\n",
    "# To view the ascii chart:\n",
    "man 7 ascii\n",
    "\n",
    "# To see config:\n",
    "cat /private/etc/man.conf\n",
    "\n",
    "# To check the existence of a keyword in all of man pages:\n",
    "man -k <keyword>\n",
    "\n",
    " tldr:man \n",
    "# man\n",
    "# Format and display manual pages.\n",
    "# More information: <https://www.man7.org/linux/man-pages/man1/man.1.html>.\n",
    "\n",
    "# Display the man page for a command:\n",
    "man command\n",
    "\n",
    "# Display the man page for a command from section 7:\n",
    "man 7 command\n",
    "\n",
    "# List all available sections for a command:\n",
    "man -f command\n",
    "\n",
    "# Display the path searched for manpages:\n",
    "man --path\n",
    "\n",
    "# Display the location of a manpage rather than the manpage itself:\n",
    "man -w command\n",
    "\n",
    "# Display the man page using a specific locale:\n",
    "man command --locale=locale\n",
    "\n",
    "# Search for manpages containing a search string:\n",
    "man -k \"search_string\"\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c7a282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import init_empty_weights, infer_auto_device_map, load_checkpoint_and_dispatch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dfcdbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tune_gorilla import prep_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abcc68c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = prep_model(\"/mnt/data/mart/test_trainer/checkpoint-625/\")\n",
    "# model = prep_model(\"/mnt/data/mart/falcon-7b-sharded-bf16/\")\n",
    "# model = prep_model(\"/mnt/data/mart/test_rewired_checkpoint/\")\n",
    "# model = prep_model(\"/mnt/data/mart/with_description/\")\n",
    "# model = prep_model(\"/mnt/data/mart/only_call_stop/\")\n",
    "model = prep_model(\"/mnt/data/mart/gorilla-falcon-7b-hf-v0/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7416f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7d9cd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "The model 'RWForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b41a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8460d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_hf = pd.read_json('/mnt/data/mart/gorilla/data/apibench/huggingface_eval.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60a328f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "apis_list = pd.read_json('/mnt/data/mart/gorilla/data/api/huggingface_api.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95ed449c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0810d485f62b4d41bdcd19616bd09279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m cur_gen[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m req\n\u001b[1;32m      6\u001b[0m cur_gen[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected_call\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mapi_call\n\u001b[0;32m----> 7\u001b[0m sequences \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<user>: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mreq\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m<IDE-genie>: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                     \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m cur_gen[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_call\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<<<api_call>>>: (.*)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, sequences[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m generations\u001b[38;5;241m.\u001b[39mappend(cur_gen)\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:201\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/transformers/pipelines/base.py:1120\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1114\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         )\n\u001b[1;32m   1118\u001b[0m     )\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/transformers/pipelines/base.py:1127\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1126\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1127\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1128\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/transformers/pipelines/base.py:1026\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1025\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1026\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1027\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:263\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/transformers/generation/utils.py:1572\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1564\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1565\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1566\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1567\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1568\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1569\u001b[0m     )\n\u001b[1;32m   1571\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_beam_gen_mode:\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mnum_return_sequences \u001b[38;5;241m>\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mnum_beams:\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/transformers/generation/utils.py:2619\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2616\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2618\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2619\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2620\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2622\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2623\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2624\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2627\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/tiiuae/falcon-7b/2f5c3cd4eace6be6c0f12981f377fb35e5bf6ee5/modelling_RW.py:753\u001b[0m, in \u001b[0;36mRWForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeprecated_arguments\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    751\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 753\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    764\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    766\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/tiiuae/falcon-7b/2f5c3cd4eace6be6c0f12981f377fb35e5bf6ee5/modelling_RW.py:648\u001b[0m, in \u001b[0;36mRWModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001b[0m\n\u001b[1;32m    640\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    641\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    642\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         head_mask[i],\n\u001b[1;32m    646\u001b[0m     )\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 648\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43malibi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malibi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/tiiuae/falcon-7b/2f5c3cd4eace6be6c0f12981f377fb35e5bf6ee5/modelling_RW.py:385\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[0;34m(self, hidden_states, alibi, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    382\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# Self attention.\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayernorm_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43malibi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malibi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m attention_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mparallel_attn:\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/mart/anaconda4/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/tiiuae/falcon-7b/2f5c3cd4eace6be6c0f12981f377fb35e5bf6ee5/modelling_RW.py:245\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, hidden_states, alibi, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    242\u001b[0m fused_qkv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_key_value(hidden_states)  \u001b[38;5;66;03m# [batch_size, seq_length, 3 x hidden_size]\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# 3 x [batch_size, seq_length, num_heads, head_dim]\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m (query_layer, key_layer, value_layer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfused_qkv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m batch_size, q_length, _, _ \u001b[38;5;241m=\u001b[39m query_layer\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    249\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m query_layer\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, q_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generations = []\n",
    "for i, row in tqdm(eval_hf.iterrows()):\n",
    "    cur_gen = {}\n",
    "    req = re.findall(r'###.?Instruction: (.*)', row.code)[0]\n",
    "    cur_gen['request'] = req\n",
    "    cur_gen['expected_call'] = row.api_call\n",
    "    sequences = pipeline(f\"<user>: {req} \\n<IDE-genie>: \", \n",
    "                         max_length=256, \n",
    "                         do_sample=True, \n",
    "                         top_k=10, \n",
    "                         num_return_sequences=1, \n",
    "                         eos_token_id=tokenizer.eos_token_id,)\n",
    "    cur_gen['generated_call'] = re.findall(r'<<<api_call>>>: (.*)\\n', sequences[0]['generated_text'])[0]\n",
    "    generations.append(cur_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4843cb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "req = 'I want to generate images based on textual input.'\n",
    "sequences = pipeline(f\"<user>: {req} \\n<IDE-genie>: \", \n",
    "                         max_length=256, \n",
    "                         do_sample=True, \n",
    "                         top_k=10, \n",
    "                         num_return_sequences=1, \n",
    "                         eos_token_id=tokenizer.eos_token_id,)\n",
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "063ed079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated_text': '<user>: I want to generate images based on textual input. \\n<IDE-genie>: /run.sh --skip_data_prep false --skip_train true --download_model mio/tokiwa_midori'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6e8d0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same_function(str_1, str_2):\n",
    "    f1 = re.findall(r'^(.*)\\(', str_1)[0]\n",
    "    f2 = re.findall(r'^(.*)\\(', str_2)[0]\n",
    "    \n",
    "    return f1 == f2\n",
    "\n",
    "def is_same_model(str_1, str_2):\n",
    "    m1 = re.findall(r'\\((.*?)\\)', str_1)[0].split(',')[0]\n",
    "    m2 = re.findall(r'\\((.*?)\\)', str_2)[0].split(',')[0]\n",
    "    \n",
    "    return m1 == m2\n",
    "\n",
    "def is_same_functionality(str_1, str_2):\n",
    "    m1 = re.findall(r'\\((.*?)\\)', str_1)[0].split(',')[0]\n",
    "    m2 = re.findall(r'\\((.*?)\\)', str_2)[0].split(',')[0]\n",
    "    \n",
    "\n",
    "    f1 = apis_list[apis_list.api_name == m1[1:-1]].functionality\n",
    "    f2 = apis_list[apis_list.api_name == m2[1:-1]].functionality\n",
    "    \n",
    "    if (len(f1) > 0) and (len(f2) > 0):\n",
    "        print(f1.iloc[0], f2.iloc[0])\n",
    "        return f1.iloc[0] == f2.iloc[0]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61dac5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for gen in generations:\n",
    "    print(is_same_function(gen['expected_call'], gen['generated_call']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cef94b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for gen in generations:\n",
    "    print(is_same_model(gen['expected_call'], gen['generated_call']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8cd0730e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction Sentence Embeddings\n",
      "False\n",
      "Feature Extraction Fill-Mask\n",
      "False\n",
      "0\n",
      "Feature Extraction Feature Extraction\n",
      "True\n",
      "Image generation and modification based on text prompts Text-to-Image\n",
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for gen in generations:\n",
    "    print(is_same_functionality(gen['expected_call'], gen['generated_call']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "192f830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e2e29a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   5.,  62., 206., 277., 186., 107.,  41.,  20.,   6.]),\n",
       " array([  0. ,  26.3,  52.6,  78.9, 105.2, 131.5, 157.8, 184.1, 210.4,\n",
       "        236.7, 263. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(i) for i in generated_calls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0931cf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'###Instruction: Our team works on a drug development project. We need to process large amounts of biomedical text to identify entities, relations and answer questions that might be helpful.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "483f17f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\"],\n",
       " [\"AutoModel.from_pretrained('GanjinZero/UMLSBert_ENG')\"],\n",
       " [\"pipeline('audio-classification', model='superb/hubert-large-superb-er')\"],\n",
       " [\"AutoModel.from_pretrained('rasa/LaBSE')\"],\n",
       " [\"StableDiffusionPipeline.from_pretrained('dreamlike-art/dreamlike-photoreal-2.0', torch_dtype=torch.float16)\"],\n",
       " [\"Blip2ForConditionalGeneration.from_pretrained('Salesforce/blip2-flan-t5-xxl')\"],\n",
       " [\"AutoModelForCausalLM.from_pretrained('microsoft/git-large-textcaps')\"],\n",
       " [\"pipeline('object-detection', model='microsoft/chart-qa-base')\"],\n",
       " [\"pipeline('text-to-video', model='camenduru/text2-video-zero')\"],\n",
       " [\"TimesformerForVideoClassification.from_pretrained('facebook/timesformer-hr-finetuned-k600')\"],\n",
       " [\"DiffusionPipeline.from_pretrained('damo-vilab/text-to-video-ms-1.7b-legacy', torch_dtype=torch.float16, variant=fp16)\"],\n",
       " [\"pipeline('image-to-text', model='microsoft/git-base')\"],\n",
       " [\"pipeline('visual-question-answering', model='microsoft/git-base-vqav2')\"],\n",
       " [\"pipeline('question-answering', model='impira/layoutlm-invoices')\"],\n",
       " [\"pipeline('question-answering', model='Sayantan1993/layoutlmv2-base-uncased_finetuned_docvqa')\"],\n",
       " [\"AutoModel.from_pretrained('clefourrier/graphormer-base-pcqm4mv2')\"],\n",
       " [\"AutoModel.from_pretrained('sayakpaul/glpn-nyu-finetuned-diode-221228-072509')\"],\n",
       " [\"AutoModel.from_pretrained('hf-tiny-model-private/tiny-random-GLPNForDepthEstimation')\"],\n",
       " [\"DPTForDepthEstimation.from_pretrained('hf-tiny-model-private/tiny-random-DPTForDepthEstimation')\"],\n",
       " [\"AutoModelForImageClassification.from_pretrained('microsoft/swin-tiny-patch4-window7-224-bottom_cleaned_data')\"],\n",
       " [\"pipeline('object-detection', model='microsoft/detecto-large')\"],\n",
       " [\"YOLO('keremberke/yolov8m-valorant-detection')\"],\n",
       " [\"YOLO('keremberke/yolov8m-real-estate-object-detection')\\\\n \"],\n",
       " [\"SegformerForSemanticSegmentation.from_pretrained('nvidia/segformer-b0-finetuned-ade-512-512')\"],\n",
       " [\"Mask2FormerForUniversalSegmentation.from_pretrained('facebook/mask2former-swin-tiny-coco-instance')\"],\n",
       " [\"DDPMPipeline.from_pretrained('google/ddpm-celebahq-256')\"],\n",
       " [\"DDPMPipeline.from_pretrained('google/ddpm-bedroom-256')\"],\n",
       " [\"DDPMPipeline.from_pretrained('ntrant7/sd-class-butterflies-32')\"],\n",
       " [\"TimesformerForVideoClassification.from_pretrained('facebook/timesformer-base-finetuned-ssv2')\"],\n",
       " [\"TimesformerForVideoClassification.from_pretrained('facebook/timesformer-hr-finetuned-k600')\"],\n",
       " [\"timm.create_model('convnextv2_huge.fcmae_ft_in1k', pretrained=True)\"],\n",
       " [\"pipeline('zero-shot-image-classification', model='microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\"],\n",
       " [\"timm.create_model('convnextv2_huge.fcmae_ft_in1k', pretrained=True)\"],\n",
       " [\"ChineseCLIPModel.from_pretrained('OFA-Sys/chinese-clip-vit-large-patch14-336px')\"],\n",
       " [\"pipeline('sentiment-analysis', model='philschmid/distilbert-imdb')\"],\n",
       " [\"DistilbertForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\"],\n",
       " [\"pipeline('sentiment-analysis', model='lvwerra/distilbert-imdb')\"],\n",
       " [\"pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')\"],\n",
       " [\"AutoModelForSequenceClassification.from_pretrained('sileod/deberta-v3-base-tasksource-nli')\"],\n",
       " [\"AutoModelForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment')\"],\n",
       " [],\n",
       " [\"AutoModelForTokenClassification.from_pretrained('Jean-Baptiste/roberta-large-ner-english')\"],\n",
       " [\"SequenceTagger.load('flair/ner-english-ontonotes-large')\"],\n",
       " [\"AutoModel.from_pretrained('google/tapas-mini-finetuned-wtq')\\\\n \"],\n",
       " ['TabTransformer.from_config()'],\n",
       " [\"pipeline('table-question-answering', model='Meena/table-question-answering-tapas')<br /> <<<api_provider>>>: PyTorch Transformers<br /> <<<explanation>>>:1. Import the 'pipeline' function from the transformers library.\"],\n",
       " [],\n",
       " [\"pipeline('question-answering', model='LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023')\"],\n",
       " [],\n",
       " [\"pipeline('question-answering', model='deepset/tinyroberta-squad2', tokenizer='deepset/tinyroberta-squad2')\"],\n",
       " [\"pipeline('question-answering', model='seungwon12/layoutlmv2-base-uncased_finetuned_docvqa', tokenizer='seungwon12/layoutlmv2-base-uncased_finetuned_docvqa')\"],\n",
       " [\"pipeline('zero-shot-classification', model='BaptisteDoyen/camembert-base-xnli')\"],\n",
       " [\"pipeline('zero-shot-classification', model='cross-encoder/nli-deberta-v3-xsmall')\"],\n",
       " [\"pipeline('text-generation', model='sshleifer/tiny-gpt2')\"],\n",
       " [],\n",
       " [\"pipeline('translation_xx_to_yy', model='facebook/nllb-200-distilled-600M')\"],\n",
       " [],\n",
       " [\"T5Model.from_pretrained('t5-base')\"],\n",
       " [],\n",
       " [\"T5Model.from_pretrained('t5-base')\"],\n",
       " [],\n",
       " [\"pipeline('text-generation', model='PygmalionAI/pygmalion-2.7b')\"],\n",
       " [\"pipeline('text-generation', model='bigscience/bloom-7b1')\"],\n",
       " [\"BlenderbotForConditionalGeneration.from_pretrained('facebook/blenderbot-3B')\"],\n",
       " [\"pipeline('fill-mask', model='albert-base-v2')\"],\n",
       " [\"AlbertForMaskedLM.from_pretrained('uer/albert-base-chinese-cluecorpussmall')\"],\n",
       " [\"pipeline('fill-mask', model='huggingface/CodeBERTa-small-v1')\\\\n \"],\n",
       " [\"AutoModelForMaskedLM.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\\\\<<<api_provider>>>: Hugging Face Transformers\\\\<<<explanation>>>: 1. Import the necessary classes from the transformers library, such as AutoModelForMaskedLM and AutoTokenizer.\"],\n",
       " [\"SentenceTransformer('sentence-transformers/bert-base-nli-mean-tokens')\"],\n",
       " [\"SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\"],\n",
       " [\"SentenceTransformer('sentence-transformers/bert-base-nli-mean-tokens')\"],\n",
       " [],\n",
       " [\"Wav2Vec2Model.from_pretrained('jonatasgrosman/wav2vec2-large-xlsr-53-english')\\\\n \"],\n",
       " [\"Model.from_pretrained('pyannote/speaker-diarization@2.1')\"],\n",
       " [\"Wav2Vec2ForCTC.from_pretrained('facebook/wav2vec2-xlsr-53-espeak-cv-ft')\"],\n",
       " [\"WaveformEnhancement.from_hparams('enhancement_model', 'julien-c/waveform-enhancement-mp3')\"],\n",
       " [\"Wav2Vec2Model.from_pretrained('jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn')\"],\n",
       " [\"WaveformEnhancement.from_hparams('speechbrain/mtl-mimic-voicebank', 'pretrained_models/mtl-mimic-voicebank')\"],\n",
       " [\"load_model_ensemble_and_task_from_hf_hub('facebook/xm_transformer_unity_en-hk')\"],\n",
       " [\"pipeline('audio-classification', model='superb/wav2vec2-base-superb-ks')\"],\n",
       " [\"EncoderClassifier.from_hparams(source='speechbrain/lang-id-voxlingua107-ecapa', savedir='/tmp')\"],\n",
       " [\"Pipeline.from_pretrained('pyannote/voice-activity-detection')\"],\n",
       " [\"joblib.load(cached_download(hf_hub_url('julien-c/wine-quality','sklearn_model.joblib')))\"],\n",
       " [\"load_model(cached_download(hf_hub_url('danupurnomo/dummy-titanic', 'titanic_model.h5')))\"],\n",
       " [\"joblib.load('model.joblib')\"],\n",
       " [\"joblib.load('model.joblib')\"],\n",
       " [\"joblib.load('model.joblib')\"],\n",
       " [\"joblib.load('model.joblib')\"],\n",
       " [\"joblib.load('model.joblib')\"],\n",
       " [\"joblib.load(hf_hub_download('merve/tips5wx_sbh5-tip-regression','sklearn_model.joblib'))\"],\n",
       " [\"load_from_hub(repo_id='sb3/dqn-CartPole-v1',filename='{MODEL FILENAME}.zip',)\"],\n",
       " [\"StableDiffusionPipeline.from_pretrained('stabilityai/stable-diffusion-2-1-base', scheduler=EulerDiscreteScheduler.from_pretrained('stabilityai/stable-diffusion-2-1-base', subfolder=scheduler), torch_dtype=torch.float16)\"],\n",
       " [\"ControlNetModel.from_pretrained('lllyasviel/control_v11p_sd15_scribble')\"],\n",
       " [\"Swin2SRForConditionalGeneration.from_pretrained('condef/Swin2SR-lightweight-x2-64')\"],\n",
       " [\"pipeline('text2text-generation', model='salesforce/blip2-opt-6.7b')\"],\n",
       " [\"BlipForConditionalGeneration.from_pretrained('Salesforce/blip-image-captioning-large')\"],\n",
       " [\"AutoModelForQuestionAnswering.from_pretrained('uclanlp/visualbert-vqa')\"],\n",
       " [\"pipeline('text-generation', model='microsoft/git-base-coco')\"],\n",
       " [\"AutoModelForDocumentQuestionAnswering.from_pretrained('L-oenai/LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023')\"],\n",
       " [\"pipeline('question-answering', model='sultan/BioM-ELECTRA-Large-SQuAD2')\"],\n",
       " [\"LayoutLMv2ForQuestionAnswering.from_pretrained('dperales/layoutlmv2-base-uncased_finetuned_docvqa')\"],\n",
       " [\"AutoModelForDocumentQuestionAnswering.from_pretrained('tiennvcs/layoutlmv2-base-uncased-finetuned-infovqa')\"],\n",
       " [\"DeformableDepthEstimation.from_pretrained('nielsr/dpt-large-redesign')\"],\n",
       " [\"DPTForDepthEstimation.from_pretrained('hf-tiny-model-private/tiny-random-DPTForDepthEstimation')\"],\n",
       " [\"AutoModel.from_pretrained('sayakpaul/glpn-nyu-finetuned-diode-221215-092352')\"],\n",
       " [\"AutoModel.from_pretrained('sayakpaul/glpn-nyu-finetuned-diode-221116-054332')\"],\n",
       " [\"AutoModelForImageClassification.from_pretrained('microsoft/swin-tiny-patch4-window7-224-bottom_cleaned_data')\"],\n",
       " [\"ConvNextForImageClassification.from_pretrained('facebook/convnext-tiny-224')\"],\n",
       " [\"pipeline('zero-shot-classification', model='laion/CLIP-ViT-B-32-laion2B-s34B-b79K')\"],\n",
       " [\"pipeline('image-classification', model='laion/CLIP-convnext_large_d.laion2B-s26B-b102K-augreg')\"],\n",
       " [\"DetrForObjectDetection.from_pretrained('facebook/detr-resnet-50')\"],\n",
       " [\"ControlNetModel.from_pretrained('lllyasviel/sd-controlnet-seg')\"],\n",
       " [\"SegformerForSemanticSegmentation.from_pretrained('NVIDIA/segformer-b2-finetuned-ade-512-512')\"],\n",
       " [\"SegformerForSemanticSegmentation.from_pretrained('nvidia/segformer-b2-finetuned-cityscapes-1024-1024')\"],\n",
       " [\"Mask2FormerForUniversalSegmentation.from_pretrained('facebook/mask2former-swin-tiny-coco-instance')\"],\n",
       " [\"ControlNetModel.from_pretrained('lllyasviel/control_v11p_sd15_scribble')\"],\n",
       " [\"pipeline('video-classification', model='sayakpaul/videomae-base-finetuned-ucf101-subset')\"],\n",
       " [\"VideoMAEForVideoClassification.from_pretrained('MCG-NJU/videomae-large-finetuned-kinetics')\"],\n",
       " [\"AlignModel.from_pretrained('kakaobrain/align-base')\"],\n",
       " [\"timm.create_model('convnext_base.fb_in1k', pretrained=True)\"],\n",
       " [\"pipeline('image-classification', model='fxmarty/resnet-tiny-beans')\"],\n",
       " [\"pipeline('text-classification', model='Seethal/sentiment-analysis-generic-dataset')\"],\n",
       " [\"pipeline('explanation-generation', model='Qiliang/bart-large-cnn-samsum-ChatGPT_v3')\"],\n",
       " [\"T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-large-finetuned-questions')\"],\n",
       " [\"AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2')\"],\n",
       " [\"AutoModelForTokenClassification.from_pretrained('ismail-lucifer011/autotrain-name_all-904029577', use_auth_token=True)\"],\n",
       " [\"AutoModelForTokenClassification.from_pretrained('ismail-lucifer011/autotrain-job_all-903929564', use_auth_token=True)\"],\n",
       " [\"pipeline('table-question-answering', model='google/tapas-large-finetuned-wtq')\"],\n",
       " [\"BartForConditionalGeneration.from_pretrained('microsoft/tapex-large-finetuned-wikisql')\\\\n\"],\n",
       " [\"BartForConditionalGeneration.from_pretrained('microsoft/tapex-large-sql-execution')\"],\n",
       " [],\n",
       " [\"TapasForQuestionAnswering.from_pretrained('google/tapas-mini-finetuned-sqa')\"],\n",
       " [\"AutoModelForQuestionAnswering.from_pretrained('Rakib/roberta-base-on-cuad')\"],\n",
       " [],\n",
       " [\"CrossEncoder('cross-encoder/nli-deberta-v3-base')\"],\n",
       " [\"pipeline('translation_en_to_zh', model='Helsinki-NLP/opus-mt-en-zh')\"],\n",
       " [\"pipeline('summarization', model='google/pegasus-newsroom')\"],\n",
       " [\"AutoModel.from_pretrained('csebuetnlp/mT5_multilingual_XLSum')\"],\n",
       " [\"pipeline('text-generation', model='Zixtrauce/BDBot4Epoch')\"],\n",
       " [\"pipeline('text-generation', model='primaryschool-cnn')\"],\n",
       " [\"pipeline('text-generation', 'PygmalionAI/pygmalion-1.3b')\"],\n",
       " [\"AutoTokenizer.from_pretrained('Salesforce/codegen-2B-multi')\"],\n",
       " [\"BigBirdPegasusForConditionalGeneration.from_pretrained('google/bigbird-pegasus-large-bigpatent')\"],\n",
       " [],\n",
       " [\"pipeline('translation_xx_to_de', model='facebook/nllb-200-distilled-600M')\"],\n",
       " [\"Wav2Vec2Model.from_pretrained('microsoft/wavlm-large')\"],\n",
       " [\"pipeline('fill-mask', model='bert-base-cased')\"],\n",
       " [\"pipeline('fill-mask', model='albert-base-v2')\"],\n",
       " [\"SentenceTransformer('sentence-transformers/gtr-t5-base')\"],\n",
       " [\"pipeline('text-to-speech', model='mio/Artoria')\"],\n",
       " [\"load_model_ensemble_and_task_from_hf_hub('facebook/unit_hifigan_mhubert_vp_en_es_fr_it3_400k_layer11_km1000_fr_css10')\"],\n",
       " [\"load_model_ensemble_and_task_from_hf_hub('facebook/unit_hifigan_mhubert_vp_en_es_fr_it3_400k_layer11_km1000_fr_css10')\"],\n",
       " [\"load_model_ensemble_and_task_from_hf_hub('facebook/tts_transformer-fr-cv7_css10')\"],\n",
       " [\"WhisperForConditionalGeneration.from_pretrained('openai/whisper-large-v2')\"],\n",
       " [\"WhisperModel('large-v2')\"],\n",
       " [\"WhisperForConditionalGeneration.from_pretrained('openai/whisper-large')\"],\n",
       " [\"load_model_ensemble_and_task_from_hf_hub('facebook/xm_transformer_unity_en-hk')\"],\n",
       " [\"pipeline('audio-classification', model='superb/hubert-base-superb-ks')\"],\n",
       " [\"pipeline('audio-classification', model='superb/wav2vec2-base-superb-sid')\"],\n",
       " [\"AutoModelForAudioClassification.from_pretrained('MIT/ast-finetuned-speech-commands-v2')\"],\n",
       " [\"AutoModelForAudioClassification.from_pretrained('MIT/ast-finetuned-speech-commands-v2')\"],\n",
       " [\"Pipeline.from_pretrained('pyannote/speaker-diarization@2.1', use_auth_token='ACCESS_TOKEN_GOES_HERE')\"],\n",
       " [\"joblib.load('model.joblib')\"],\n",
       " [\"joblib.load('model.joblib')\"],\n",
       " [\"joblib.load('model.joblib')\"],\n",
       " [\"AutoModel.from_pretrained('hackathon-pln-es/kaggle-hackathon-pln-es-traineedition')\"],\n",
       " [\"AutoModel.from_pretrained('edbeeching/decision-transformer-gym-walker2d-expert')\"],\n",
       " [\"load_from_hub(repo_id='sb3/ppo-PongNoFrameskip-v4',filename='{MODEL FILENAME}.zip',)\"]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_calls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
